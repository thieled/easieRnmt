% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/02_translate.R
\name{translate}
\alias{translate}
\title{Preprocess and Translate Texts}
\usage{
translate(
  x,
  text_col = "text",
  id_col = NULL,
  lang_guess_col = NULL,
  targ_lang,
  model_path = NULL,
  prob_threshold = 0.25,
  und_label = "und",
  max_char = 5000,
  threads = parallel::detectCores(),
  target_lang,
  model = "opus-mt",
  seed = 42L,
  batch_size = 20L,
  max_length_tl = 512L,
  beam_size = 1L,
  deterministic = TRUE,
  verbose = TRUE,
  check_translation = FALSE,
  n_retries = 3L,
  check_threshold = 0.6,
  return_string = FALSE,
  save_dir = NULL,
  tokenize_sentences = FALSE,
  ...
)
}
\arguments{
\item{x}{Character vector or data.frame containing texts to process.}

\item{text_col}{Character, name of the text column if \code{x} is a data.frame.
Ignored if \code{x} is a character vector. Default = "text".}

\item{id_col}{Character, optional column name in the input data.frame to
preserve as an identifier. Default = NULL.}

\item{lang_guess_col}{Character, optional column name in the input data.frame
to preserve as a column named \code{lang_guess}. Default = NULL.}

\item{targ_lang}{Character, fallback language code to assign when fastText
detection is uncertain and no \code{lang_guess} is available. Required.}

\item{model_path}{Character, path to the fastText \code{lid.176.bin} model.
Defaults to \code{~/.cache/easieRnmt/lid.176.bin}.}

\item{prob_threshold}{Numeric, threshold below which the detected language is
replaced by \code{und_label}. Default = 0.25.}

\item{und_label}{Character, label for undefined language. Default = "und".}

\item{max_char}{Integer, maximum number of characters per text after cleaning.
Texts longer than this are truncated. Default = 5000.}

\item{threads}{Integer, number of threads for fastText. Default =
\code{parallel::detectCores()}.}

\item{target_lang}{Character, target language for translation.}

\item{model}{Character, translation model (default "opus-mt").}

\item{seed}{Integer, random seed (default 42).}

\item{batch_size}{Integer, batch size for translation (default 20L).}

\item{max_length_tl}{Integer, maximum token length (default 512L).}

\item{beam_size}{Integer, beam size for translation (default 1L).}

\item{deterministic}{Logical, enforce deterministic cudnn ops (default TRUE).}

\item{verbose}{Logical, whether to print progress messages. Default = TRUE.}

\item{check_translation}{Logical, perform retry check (default FALSE).}

\item{n_retries}{Integer, number of retries if check fails (default 3L).}

\item{check_threshold}{Numeric, threshold for ratio of unique tokens
(target / source) below which retries are attempted (default 0.6).}

\item{return_string}{Logical, if TRUE, return only the translated character vector. Default = FALSE.}

\item{save_dir}{Optional character path. If provided, saves each processed
subset as an \code{.rds} file with its language/part name.}

\item{tokenize_sentences}{Logical, if TRUE, split long texts into sentences
during preprocessing and reassemble them after translation. Default = FALSE.}

\item{...}{Additional parameters passed on to \code{clean_text()} during preprocessing.}
}
\value{
A data.table with original data plus translation results merged in.
}
\description{
Detects languages, reprocesses uncertain cases, optionally
splits long texts into sentences, splits the input into homogeneous
language groups, and calls the Python translator
(\code{easynmt_translate()}) on each group.
}
